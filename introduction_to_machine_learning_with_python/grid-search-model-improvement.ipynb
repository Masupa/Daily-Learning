{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    GRID-SEARCH\n",
    "    \n",
    "    Grid search is a technique that can be used to improve a model's performance on a given datasets\n",
    "    by searching through a space of parameters and finding parameters that increase the model's\n",
    "    performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Sample illustration:\n",
    "    \n",
    "    Let's train a model that identifies the different plant species of the iris flower, using the iris\n",
    "    dataset in-built in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris  # Load iris dataset\n",
    "from sklearn.model_selection import train_test_split  # Split data into train and test sets\n",
    "from sklearn.model_selection import cross_val_score  # Cross validation split\n",
    "\n",
    "# These are the models we want to train\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree Model\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression Model\n",
    "from sklearn.svm import SVC  # Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracies: [0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
      "Mean Accuracy: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_scores = cross_val_score(tree, data, target, cv=5)\n",
    "\n",
    "print(\"Model Accuracies: {}\".format(tree_scores))\n",
    "print(\"Mean Accuracy: {}\".format(np.mean(tree_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracies: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Mean Accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_scores = cross_val_score(log_reg, data, target, cv=5)\n",
    "\n",
    "print(\"Model Accuracies: {}\".format(log_scores))\n",
    "print(\"Mean Accuracy: {}\".format(np.mean(log_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracies: [0.96666667 0.96666667 0.96666667 0.93333333 1.        ]\n",
      "Mean Accuracy: 0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "svc = SVC()\n",
    "svm_scores = cross_val_score(svc, data, target, cv=5)\n",
    "\n",
    "print(\"Model Accuracies: {}\".format(svm_scores))\n",
    "print(\"Mean Accuracy: {}\".format(np.mean(svm_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The mean accuracy scores above give us an idea about how well our model's generalizing on a new\n",
    "    dataset. Once we've understood how well our model's are performing, the other main question to ask is: \n",
    "    \n",
    "        ??? \"Can we improve their performance?\"\n",
    "    \n",
    "    Yes, we can improve their performance by searching through a space of model parameters, and evaluating\n",
    "    the accuracy scores (or regression metrics - for regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9733333333333334\n",
      "Best Params: {'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# Improving Decision Trees\n",
    "\n",
    "# Maximum depth is a feature for decision trees\n",
    "# Let's say we want to see how our model's performance\n",
    "# changes by tweaking this parameter\n",
    "\n",
    "list_max_depth = [3, 6, 12, 18, 24, 30, 40, 50]  # Does this parameter influence our model's accuracy?\n",
    "\n",
    "best_score_ = 0  # Accuracy scores range [0, 100]\n",
    "\n",
    "for max_depth in list_max_depth:\n",
    "    clf_tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    scores = cross_val_score(clf_tree, data, target, cv=5)\n",
    "    mean_score = np.mean(scores)\n",
    "    \n",
    "    if mean_score > best_score_:\n",
    "        best_score_ = mean_score\n",
    "        best_params_ = {\n",
    "            \"max_depth\": max_depth\n",
    "        }\n",
    "        \n",
    "print(\"Best Score: {}\".format(best_score_))\n",
    "print(\"Best Params: {}\".format(best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We observe that the accuracy of the tree classifier improved by using a max_depth of 3.\n",
    "    \n",
    "    Can we improve this further by adding another search parameter, hencing searching through\n",
    "    a combition of the max_depth + the additional parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9733333333333334\n",
      "Best Params: {'max_depth': 3, 'max_leaf_nodes': 5}\n"
     ]
    }
   ],
   "source": [
    "# Adding another parameter\n",
    "\n",
    "list_max_depth = [3, 6, 12, 18, 24, 30, 40, 50]\n",
    "list_max_leaf_nodes = [4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "best_score_ = 0\n",
    "\n",
    "for max_depth in list_max_depth:\n",
    "    for max_leaf_nodes in list_max_leaf_nodes:\n",
    "        \n",
    "        tree = DecisionTreeClassifier(max_depth=max_depth, max_leaf_nodes=max_leaf_nodes)\n",
    "        scores = cross_val_score(tree, data, target, cv=5)\n",
    "        mean_score = np.mean(scores)\n",
    "        \n",
    "        if mean_score > best_score_:\n",
    "            best_score_ = mean_score\n",
    "            best_params_ = {\n",
    "                \"max_depth\": max_depth,\n",
    "                \"max_leaf_nodes\": max_leaf_nodes\n",
    "            }\n",
    "            \n",
    "print(\"Best Score: {}\".format(best_score_))\n",
    "print(\"Best Params: {}\".format(best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Here, we observe that our accuracy score hasn't improved with the addition of max_lead_nodes. This\n",
    "    entails that 'max_leaf_nodes' has no impact on the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Improve Logistic Regression`\n",
    "\n",
    "    Without performing any hyper-parameter tuning, the accuracy of this model is 97%. Here, I introduce\n",
    "    a search space of parameters which will be used in the model to evaluate it's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's test these parameters; here, we choose to be\n",
    "# # ignorant about them, as the focus is in finding\n",
    "# # parameters\n",
    "\n",
    "# penalty_space = ['l1', 'elasticnet']\n",
    "# C = [0.01, 0.1, 0.5, 1.0, 1.3, 1.5]\n",
    "\n",
    "# best_score_ = 0\n",
    "\n",
    "# # Loop through all paramters; 24 combinations parameters\n",
    "# for penalty in penalty_space:\n",
    "#     for c in C:\n",
    "#         log_reg = LogisticRegression(penalty=penalty, C=c, max_iter=1000)\n",
    "#         mean_score = np.mean(cross_val_score(log_reg, data, target, cv=5))\n",
    "        \n",
    "#         if mean_score > best_score_:\n",
    "#             best_score_ = mean_score\n",
    "#             best_params_ = {\n",
    "#                 \"penalty\": penalty,\n",
    "#                 \"C\": c\n",
    "#             }\n",
    "            \n",
    "# print(\"Best Score: {}\".format(best_score_))\n",
    "# print(\"Best Params: {}\".format(best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Improve Support Vector Machine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9800000000000001\n",
      "Best Params: {'penalty': 'l2', 'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Parameter Space\n",
    "C_space = [0.001, 0.01, 0.1, 1.0, 10, 100]\n",
    "gamma_space = [0.001, 0.01, 0.1, 1.0, 10, 100]\n",
    "\n",
    "best_score_ = 0\n",
    "\n",
    "for C in C_space:  # Loop through 'C_space'\n",
    "    for gamma in gamma_space:  # Loop through gamma_space\n",
    "        \n",
    "        # Instantiate SVM Classifier with params\n",
    "        svm_clf = SVC(C=C, gamma=gamma)\n",
    "        # Cross Validation Scores - Model Generalization\n",
    "        scores = cross_val_score(svm_clf, data, target, cv=5)\n",
    "        # Mean CV Scores\n",
    "        mean_score = np.mean(scores)\n",
    "        \n",
    "        if mean_score > best_score_:\n",
    "            best_score_ = mean_score\n",
    "            best_params = {\n",
    "                'C': C,\n",
    "                'gamma': gamma\n",
    "            }\n",
    "            \n",
    "print(\"Best Score: {}\".format(best_score_))\n",
    "print(\"Best Params: {}\".format(best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Observe how the model's accuracy has improved from 96% to 96% by searching through a parameter space\n",
    "    for parameters that yield better performance.\n",
    "    \n",
    "    This is Grid-search cv is nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid_search_implementation import GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a70ea426a1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/machine_learning/introduction_to_machine_learning_with_python/grid_search_implementation.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \"\"\"\n\u001b[1;32m     30\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTraining\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTraining\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mground\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \"\"\"\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "params = {\n",
    "    'gamma': [0.001, 0.01, 0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearch(model=svc, params=params, cv=5).fit(X_train=data, y_train=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
